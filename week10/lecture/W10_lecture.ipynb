{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1IhSV4-OYyR"
   },
   "source": [
    "# Week 10: Sentiment Analysis\n",
    "\n",
    "Our task this week is as follows:\n",
    "* Get to know Python dictionaries\n",
    "* Learn about sentiment analysis, and learn how to use the sentiment analysis package in TextBlob\n",
    "* Discuss limitations of lexicon-based approach and look at how we can overcome some of them\n",
    "* Perform a small \"who wore it better\" competition between TextBlob with VADER (algorithm audit)\n",
    "* Load a novel into a dataframe, sentence by sentence.\n",
    "* Record the sentiment values for each sentence in that dataframe\n",
    "* Extract the sentences identified as the \"happiest\" and the \"saddest\" by the sentiment analysis system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUF2OpiRESj_"
   },
   "source": [
    "## Python Dictionaries\n",
    "\n",
    "Before we get to sentiment analysis, we need to introduce another Python data type, which arguably can be a faviourite for English majors: dictionaries\n",
    "\n",
    "As [Melanie Walsh explains](https://melaniewalsh.github.io/Intro-Cultural-Analytics/02-Python/11-Dictionaries.html), dictionaries are mainly differentiated from `list`s by their use of **key-value pairs**. Whereas we access items in a list by their index position, we access the **values** of items in a dictionary by their **key**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuXq2hmtErfD"
   },
   "source": [
    "Python dictionaries are always surrounded by curly brackets `{ }`. You can make a dictionary in this manner:\n",
    "\n",
    "```\n",
    "variable_name = {\n",
    "   'key1': value1,\n",
    "   'key2': value2,\n",
    "   'key3': value3,\n",
    "}\n",
    "```\n",
    "Note:\n",
    "- Keys are `string`s; values can be of any data type.\n",
    "- Note that a `,` comes between each key-value pair your define\n",
    "- You don't need to arrange things like this typographically, with key-values pairs each on their own line, but it does make things look prettier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGpK8XdSE5U6"
   },
   "source": [
    "Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xocUqUNNE3W7"
   },
   "outputs": [],
   "source": [
    "writers = {\n",
    "    \"William Shakespeare\": 1564,\n",
    "    \"Jane Austen\": 1775,\n",
    "    \"Leo Tolstoy\": 1828,\n",
    "    \"Gabriel Garcia Marquez\": 1927,\n",
    "    \"Margaret Atwood\": 1939,\n",
    "}\n",
    "\n",
    "print(writers[\"William Shakespeare\"])\n",
    "\n",
    "writers[\"Virginia Woolf\"] = 1882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3PqsUUjIFt4E",
    "outputId": "12d3d5f4-85f5-4724-b9c6-40f79522fa68"
   },
   "outputs": [],
   "source": [
    "writers = {\n",
    "    \"William Shakespeare\": [1564, 1616],\n",
    "    \"Jane Austen\": [1775, 1817],\n",
    "    \"Leo Tolstoy\": [1828, 1910],\n",
    "    \"Gabriel Garcia Marquez\": [1927, 2014],\n",
    "    \"Margaret Atwood\": [1939, None],\n",
    "    \"Virginia Woolf\": [1882, 1941]\n",
    "}\n",
    "writers[\"Margaret Atwood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31NM79PxG_hV",
    "outputId": "6665d54a-5a42-4423-cc34-c3fb8dd10c57"
   },
   "outputs": [],
   "source": [
    "writers_in_20th_century = []\n",
    "\n",
    "for writer in writers: #we go over the KEYS (writer names) this way\n",
    "    birth_year = writers[writer][0]\n",
    "    death_year = writers[writer][1]\n",
    "    #birth_year, death_year = writers[writer] #alternative way\n",
    "    still_alive =  death_year is None\n",
    "    if (birth_year <= 2000 and (still_alive or death_year >= 1901)):\n",
    "        writers_in_20th_century.append(writer)\n",
    "\n",
    "writers_in_20th_century"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lSILvC4MHpe4",
    "outputId": "a17534f0-afbe-4e57-dc61-a01095bf5237"
   },
   "outputs": [],
   "source": [
    "writers = {\n",
    "    \"William Shakespeare\": {\n",
    "        \"country\": \"England\",\n",
    "        \"birth_year\": 1564,\n",
    "        \"death_year\": 1616\n",
    "    },\n",
    "    \"Jane Austen\": {\n",
    "        \"country\": \"England\",\n",
    "        \"birth_year\": 1775,\n",
    "        \"death_year\": 1817\n",
    "    },\n",
    "    \"Leo Tolstoy\": {\n",
    "        \"country\": \"Russia\",\n",
    "        \"birth_year\": 1828,\n",
    "        \"death_year\": 1910\n",
    "    },\n",
    "    \"Gabriel Garcia Marquez\": {\n",
    "        \"country\": \"Colombia\",\n",
    "        \"birth_year\": 1927,\n",
    "        \"death_year\": 2014\n",
    "    },\n",
    "    \"Margaret Atwood\": {\n",
    "        \"country\": \"Canada\",\n",
    "        \"birth_year\": 1939,\n",
    "        \"death_year\": None  # Still living\n",
    "    },\n",
    "    \"Virginia Woolf\": {\n",
    "        \"country\": \"England\",\n",
    "        \"birth_year\": 1882,\n",
    "        \"death_year\": 1941\n",
    "    }\n",
    "}\n",
    "\n",
    "writers[\"Gabriel Garcia Marquez\"][\"country\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wi0yqWViOYyt"
   },
   "source": [
    "## Iterating Through Dictionaries\n",
    "\n",
    "You can iterate through dictionaries â€” but first you need to specify, by calling the appropriate method, if you want to iterate over keys, values, of key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Pr3hrQ5ZK3E"
   },
   "outputs": [],
   "source": [
    "carnivores = {\n",
    "    \"python\": \"A large heavy-bodied nonvenomous snake that kills poor prey by constriction and asphyxiation\",\n",
    "    \"panda\": \"A large bearlike mammal that, while technically a carnivore, is in practice a vegetarian, eating only bamboo\",\n",
    "    \"blob\": \"A third-party Python library that slowly kills you by sucking up all of your time, because the textual analysis it facilitates is so fascinating\",\n",
    "    \"kitten\": \"A delightful, fuzzy creature whose natural prey is cat food (dry or wet) and, especially, treats\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J58tLPAJzkkY"
   },
   "source": [
    "We can loop through KEYS (two ways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4rwgexs-ZVyF",
    "outputId": "2696981a-cfd6-43bb-c9dd-e37396e59935"
   },
   "outputs": [],
   "source": [
    "for key in carnivores:\n",
    "    print(f\"I am so afraid of {key.upper()}S!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yEeEB75KOYyt",
    "outputId": "e2dc9562-c3ba-41b6-d27a-df7bea79b7e9"
   },
   "outputs": [],
   "source": [
    "for key in carnivores.keys():\n",
    "    print(f\"I am so afraid of {key.upper()}S!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9I754luZz1Ej"
   },
   "source": [
    "That, of course, allows us to do something with values as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C5nT9J51zr_r",
    "outputId": "acaacd75-ec2e-4b62-9660-4aa83df0821b"
   },
   "outputs": [],
   "source": [
    "for creature in carnivores:\n",
    "    print(f\"Why I am so afraif of {creature}s?\")\n",
    "    print(f\"Because {creature} is {carnivores[creature].lower()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LW7RTS000UAq"
   },
   "source": [
    "Or we can loop through values directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myoW4Hn6OYyu",
    "outputId": "2668cad1-0966-49d1-833c-c4dd12aafee6"
   },
   "outputs": [],
   "source": [
    "for value in carnivores.values():\n",
    "    print(f\"Did you know there is a kind of carnivore that is {value}???\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVthxfFE0Ykc"
   },
   "source": [
    "Difficult to remember at first, but there is a useful bit of Python syntax called unpacking, which we can rely on to loop through both keys and values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3NIY-xUOYyu",
    "outputId": "f8611553-484e-425e-c767-e8c86d3f2aac",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, value in carnivores.items():\n",
    "    print(f\"A {key} is {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TiWsBadIFWj"
   },
   "source": [
    "# Sentiment Analysis. Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROy9ahkqk4In"
   },
   "source": [
    "We will\n",
    "- show (and use) the simplest version of approaching sentiment analysis -- bag-of-words dictionary based approach\n",
    "- briefly discuss what are the main disadvantages\n",
    "- discuss the main heuristics we can apply to critically analyze algorithms\n",
    "- look how we can improve on the simplest version and how to assess if it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q85f82BC3tM0"
   },
   "source": [
    "We also employ a subset of an approach called \"algorithmic audit\" trying to critically evaluate what the algorithm does, what is it (not) good for, what are the biases -- think about the questions we have for datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install textblob\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0KftT6ot2GLk",
    "outputId": "365b6dba-70af-40b5-fc1d-08ee8e2ef105"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "\n",
    "blob = TextBlob(carnivores[\"panda\"])\n",
    "print(blob)\n",
    "print(f\"Polarity {blob.sentiment.polarity}\")\n",
    "print(f\"Subjectivity {blob.sentiment.subjectivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4UfPehP4I__"
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(carnivores[\"python\"])\n",
    "print(blob)\n",
    "print(f\"Polarity {blob.sentiment.polarity}\")\n",
    "print(f\"Subjectivity {blob.sentiment.subjectivity}\")\n",
    "\n",
    "blob = TextBlob(carnivores[\"kitten\"])\n",
    "print(blob)\n",
    "print(f\"Polarity {blob.sentiment.polarity}\")\n",
    "print(f\"Subjectivity {blob.sentiment.subjectivity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ud6SbFP74cfi"
   },
   "source": [
    "Word-based approach to sentiment analysis assigns some numeric score (positive or negative) to the word. And sums/averages over the word scores.\n",
    "\n",
    "Let's audit how this would work on the examples for which we know/can think of the answers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P02GcE-u3T8R",
    "outputId": "fc6830a2-98b0-41a3-84fd-76c9a4aec9f6"
   },
   "outputs": [],
   "source": [
    "print(TextBlob(\"awful\").polarity)\n",
    "print(TextBlob(\"great\").polarity)\n",
    "print(TextBlob(\"window\").polarity)\n",
    "print(TextBlob(\"not great\").polarity)\n",
    "print(TextBlob(\"not so great\").polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkHksLRg4Lf_"
   },
   "source": [
    "- What other cases you can think of when this approach could fail?\n",
    "- When it might be good enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dve13M5H44cb"
   },
   "source": [
    "Alternative algorithm:\n",
    "\n",
    "  > VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.\n",
    "  [VADER readme](https://github.com/cjhutto/vaderSentiment/tree/master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Md_raiPh5Sq8"
   },
   "source": [
    "> [VADER aims to properly handle] sentences with:\n",
    "\n",
    "> - typical negations (e.g., \"*not* good\")\n",
    "- use of contractions as negations (e.g., \"*wasn't* very good\")\n",
    "- conventional use of **punctuation** to signal increased sentiment intensity (e.g., \"Good!!!\")\n",
    "- conventional use of **word-shape** to signal emphasis (e.g., using ALL CAPS for words/phrases)\n",
    "- using **degree modifiers** to alter sentiment intensity (e.g., intensity *boosters* such as \"very\" and intensity *dampeners* such as \"kind of\")\n",
    "- understanding many **sentiment-laden slang** words (e.g., 'sux')\n",
    "- understanding many sentiment-laden **slang words as modifiers** such as 'uber' or 'friggin' or 'kinda'\n",
    "- understanding many sentiment-laden **emoticons** such as :) and :D\n",
    "- translating **utf-8 encoded emojis** such as ðŸ’˜ and ðŸ’‹ and ðŸ˜\n",
    "- understanding sentiment-laden **initialisms and acronyms** (for example: 'lol')\n",
    "\n",
    "Take a look at [VADER paper](https://ojs.aaai.org/index.php/ICWSM/article/view/14550/14399)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMi0V-TP6vD8"
   },
   "source": [
    "## So, let's set up our small investigation, comparing VADER and TextBlob approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6PjJ-rI_gxA"
   },
   "source": [
    "1. Define (tricky) examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGRyfWkROofM",
    "outputId": "86aa9fbc-3bfa-4cc7-b40b-9274574786f7"
   },
   "outputs": [],
   "source": [
    "examples_bow = [\n",
    "    \"It was the best of times, it was the worst of times.\",\n",
    "    \"I love how tragic her story is; it makes me feel alive.\",\n",
    "    \"That poem wasnâ€™t bad at all!\",\n",
    "    \"The characterâ€™s demise was inevitable; simply tragic.\",\n",
    "    \"Oh, fantastic... yet another twist ending.\",\n",
    "    \"I couldnâ€™t put the book down; it was haunting, to say the least.\",\n",
    "    \"She was calm, almost too calm, like the eye of a storm.\",\n",
    "    \"The protagonist had a truly unforgettable experience.\",\n",
    "    \"Thank goodness itâ€™s over. That was exhausting.\",\n",
    "    \"This plot twist is simply too much... breathtaking!\",\n",
    "    \"Wow, thanks for ruining my day with that spoiler! ðŸ˜’\",\n",
    "    \"Absolutely loved the movie... except for that ending, ugh!\",\n",
    "    \"Canâ€™t believe I waited hours for this. What a waste!\",\n",
    "    \"OMG, this is the best thing I've seen all week!!!\",\n",
    "    \"This product is seriously underrated, honestly amazing!\",\n",
    "    \"LOL, yeah right, as if this would actually work... ðŸ™„\",\n",
    "    \"Finally finished it... mixed feelings, to be honest.\",\n",
    "    \"You have to read this bookâ€”itâ€™s like nothing else!\",\n",
    "    \"Just what I needed... another delay. Fantastic. ðŸ¤¦â€â™‚ï¸\",\n",
    "    \"I'm impressed! Didnâ€™t expect it to be this good!\"\n",
    "]\n",
    "\n",
    "print(len(examples_bow))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbCCuPrC_crO"
   },
   "source": [
    "2. Formulate how the results should look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VlXhcPZt_X4u"
   },
   "outputs": [],
   "source": [
    "audit_results = {\n",
    "    \"Sentence\": [],\n",
    "    \"VADER Sentiment\": [],\n",
    "    \"VADER Score\": [],\n",
    "    \"TextBlob Sentiment\": [],\n",
    "    \"TextBlob Polarity\": [],\n",
    "    \"Difference Detected\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdGSJlX77GMu"
   },
   "source": [
    "3. Set up VADER and TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIhp4gYZ6oNm",
    "outputId": "c526b4dd-739a-4e5b-b5c7-75d685db9366"
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "print(vader_analyzer.polarity_scores(carnivores[\"panda\"]))\n",
    "print(vader_analyzer.polarity_scores(carnivores[\"python\"]))\n",
    "print(vader_analyzer.polarity_scores(carnivores[\"kitten\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKZEsBMG8M2i",
    "outputId": "131138eb-e64d-466b-d457-46b07e669dc5"
   },
   "outputs": [],
   "source": [
    "print(vader_analyzer.polarity_scores(carnivores[\"kitten\"])['compound'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8oUINn8_tOg"
   },
   "source": [
    "4. Analyze sentiment and write down the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "p1lFLkOZ67NK",
    "outputId": "9302eb58-a713-4b50-9f2f-d2716a914f51"
   },
   "outputs": [],
   "source": [
    "for sentence in examples_bow:\n",
    "    # VADER sentiment\n",
    "    vader_scores = vader_analyzer.polarity_scores(sentence)\n",
    "    vader_sentiment = \"Positive\" if vader_scores['compound'] >= 0.05 else \"Negative\" if vader_scores['compound'] <= -0.05 else \"Neutral\"\n",
    "\n",
    "\n",
    "    # TextBlob sentiment\n",
    "    blob = TextBlob(sentence)\n",
    "    blob_polarity = blob.sentiment.polarity\n",
    "    blob_subjectivity = blob.sentiment.subjectivity\n",
    "    blob_sentiment = \"Positive\" if blob_polarity > 0 else \"Negative\" if blob_polarity < 0 else \"Neutral\"\n",
    "\n",
    "    # Detect if there is a difference in sentiment\n",
    "    difference_detected = vader_sentiment != blob_sentiment\n",
    "\n",
    "    # Append results to the data dictionary\n",
    "    audit_results[\"Sentence\"].append(sentence)\n",
    "    audit_results[\"VADER Sentiment\"].append(vader_sentiment)\n",
    "    audit_results[\"VADER Score\"].append(vader_scores['compound'])\n",
    "    audit_results[\"TextBlob Sentiment\"].append(blob_sentiment)\n",
    "    audit_results[\"TextBlob Polarity\"].append(blob_polarity)\n",
    "    audit_results[\"Difference Detected\"].append(difference_detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oETSHQh_24J"
   },
   "source": [
    "5. Transform results in analysis-friendly form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baO4LQtB_2hP"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame from dictionary with column names as keys and column data as lists of values\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(audit_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Hi7z59M_9hW"
   },
   "source": [
    "6. Look at the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "x3KwJFw08aYW",
    "outputId": "c41898b4-8459-477b-d0d7-27e9fc7ea5de"
   },
   "outputs": [],
   "source": [
    "df[df[\"Difference Detected\"] == True]\n",
    "## or just\n",
    "#df[df[\"Difference Detected\"]\n",
    "## why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cOsf95RL82KK",
    "outputId": "fce1c46c-cbb4-4231-8299-06c354393b21"
   },
   "outputs": [],
   "source": [
    "len(df[df[\"Difference Detected\"] == True]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "CzLStWzP9qq4",
    "outputId": "1df99166-a8b4-479d-895f-457eefcf6516"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df[\"VADER Sentiment\"], df[\"TextBlob Sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUCfvOolOnVf"
   },
   "source": [
    "- What do we think about the results?\n",
    "- Key question: How typical they are for tasks at hand? What other troubles we may encounter?\n",
    "- What extra questions should we ask ourselves?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ryB58HjOYyU"
   },
   "source": [
    "# Getting back to TextBlob\n",
    "\n",
    "\n",
    "\n",
    "The [documentation for TextBlob](https://textblob.readthedocs.io/en/dev/) isn't the best, but the default sentiment system is based on a tool called [pattern](https://github.com/clips/pattern), which employs a sentiment lexicon â€” a list of words with values, many of them hand-coded.\n",
    "- You can see the source code [here](https://github.com/sloria/TextBlob/blob/6396e24e85af7462cbed648fee21db5082a1f3fb/textblob/en/__init__.py#L8) (around line 80): it basically averages the sentiment scores for the all the words in the span, and applies some rule-based heuristics to identify negations.\n",
    "- You can see the full lexicon [here](https://github.com/sloria/TextBlob/blob/6396e24e85af7462cbed648fee21db5082a1f3fb/textblob/en/__init__.py#L8); it's mostly adjective-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBeENwp_OYyV",
    "outputId": "d643bd32-42af-46ed-fabf-8786188e05b2"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kAj6WIiLOYyW",
    "outputId": "8c3f5f4a-a15f-47e1-bd91-df353aac5cf3"
   },
   "outputs": [],
   "source": [
    "TextBlob(\"Neil Young is the greatest artist to come out of this country\").polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pGNWCH5YOYyY",
    "outputId": "422e6809-a450-47df-8b41-621273f4001b"
   },
   "outputs": [],
   "source": [
    "TextBlob(\"I hate Neil Young and his stupid, whiny voice\").polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GdLUM4leOYyY",
    "outputId": "890d0e08-711c-46b2-841b-07cf4f2e1062"
   },
   "outputs": [],
   "source": [
    "TextBlob(\"Sometimes I feel like Neil Young is the greatest singer of his generation\").polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hd9OTbviOYyZ",
    "outputId": "03d4211c-1a20-4401-d964-e55fb55f88d2"
   },
   "outputs": [],
   "source": [
    "TextBlob(\"Neil Young isnâ€™t the worst Canadian musician\").polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_OAEm3DOYya",
    "outputId": "ce09d664-1dff-46b8-fec0-1d0710b9b6ca"
   },
   "outputs": [],
   "source": [
    "TextBlob(\"Oh yeah, Neil Youngâ€™s voice is as lovely as Josh Grobanâ€™s\").polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jBePMBJOYya",
    "outputId": "f1e99fdc-f544-490b-8161-8217a180431c"
   },
   "outputs": [],
   "source": [
    "TextBlob(\"Hating on amazing music isnâ€™t something Iâ€™m known for\").polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbLQ9Mn7OYyb",
    "outputId": "7c689189-efe0-418d-f305-a8aa635ff9da"
   },
   "outputs": [],
   "source": [
    "TextBlob(\"Neil Young\").polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Gck-SWmOYyf"
   },
   "source": [
    "The way we work with TextBlob is first by \"blobbing\" a string of text (aka, turning it from a string to a TextBlob object). This is done by passing the string as argument to the `TextBlob` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_QnN3jjOYyf"
   },
   "outputs": [],
   "source": [
    "text = \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TK2XO7HpOYyf"
   },
   "outputs": [],
   "source": [
    "pride_blob = TextBlob(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "ZRGN8XPnOYyf",
    "outputId": "b4319c86-9796-439b-aa8e-cd28f94ccf13"
   },
   "outputs": [],
   "source": [
    "type(pride_blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5fFv4yeOYyg"
   },
   "source": [
    "## Using TextBlob to Tokenize Strings and Split Them Into Sentences\n",
    "\n",
    "Once a text is blobbed, we can start calling the special TextBlob methods on it. Note that TextBlob methods don't take arguments, and indeed don't even have the usual method syntax of being followed by `()` â€” which I personally find a bit ugly.\n",
    "\n",
    "Let's look at two to start with:\n",
    "- `blob.words`: This tokenizes the string, turning into words. We've been accomplishing this with Python's built-in `string.split()` for many weeks now, then doing some extra stuff like removing punctuation with regular expressions. TextBlob does it all in one fell swoop, and does a good job with it â€” although we get less control over the process, and I personally prefer our previous method (can you see why??). The object it returns behaves like a `list`.\n",
    "- `blob.sentences`: This returns all the sentences in a string. We've been accomplishing this with `string.split(\".\")`. This does exactly the same thing, from what I can tell; for instance, it isn't smart enough to also split on `?` or `!`, and it is just as confused by contractions like `per cent.`. The object it returns again behaves like a `list`'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnopb6KCOYyg",
    "outputId": "fd48c57b-e04c-402e-8a70-3091144c2109"
   },
   "outputs": [],
   "source": [
    "pride_blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "p0UU-uUuOYyg",
    "outputId": "4c3c246f-4b14-4df4-adb8-b3a9f856c5da"
   },
   "outputs": [],
   "source": [
    "type(pride_blob.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "xdF6cjcBOYyh",
    "outputId": "bc47b04d-604b-46c6-dc2c-c7d56f0b5f23"
   },
   "outputs": [],
   "source": [
    "pride_blob.words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FAA5V2mMOYyh",
    "outputId": "b5de755d-8874-4f7d-a4af-1ea8a5efce7b"
   },
   "outputs": [],
   "source": [
    "for word in pride_blob.words:\n",
    "    print(word.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "hNJXbqcVOYyh",
    "outputId": "ba8bb919-52c1-4a5b-a9c8-58a001d53c2c"
   },
   "outputs": [],
   "source": [
    "sot4 = open(\"sign-of-four.txt\", encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdS8xhz2OYyn"
   },
   "outputs": [],
   "source": [
    "sot4_blob = TextBlob(sot4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c8W_p1HOYyn"
   },
   "outputs": [],
   "source": [
    "sot4_blob.words[255:269]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4uO68E5OYyo"
   },
   "outputs": [],
   "source": [
    "sot4_blob.sentences[9:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5FqBAzNOYyo"
   },
   "source": [
    "### TextBlob Word Counts... and Python Dictionaries\n",
    "\n",
    "TextBlob has another use method, `blob.word_counts`, which returns a list of the most commonly used terms in a document, along with a count for each of those words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snCw7Q6UOYyo"
   },
   "outputs": [],
   "source": [
    "pride_blob.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjMIpT6MOYyo"
   },
   "outputs": [],
   "source": [
    "sot4_blob.word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42oe72K7OYyo"
   },
   "source": [
    "**Python data type** returned by the `blob.words_counts` method â€” well, that's not a `list` at all, but rather a **dictionary (`dict`)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szg3iSPqOYyu"
   },
   "outputs": [],
   "source": [
    "sot4_counts = sot4_blob.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WA1b1q5rOYyu"
   },
   "outputs": [],
   "source": [
    "type(sot4_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NBun8OMOYyu"
   },
   "outputs": [],
   "source": [
    "sot4_counts['cocaine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqLFqn0VOYyv"
   },
   "source": [
    "By the way, since `blob.word_counts` produces a dictionary-like object in which each key is a unique word... can you tell me the one-line command we could use use to calculate the TTR of any TextBlob object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-niK-ZZGOYyv"
   },
   "outputs": [],
   "source": [
    "# We'll figure this one out together..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThrkAeTSOYyv"
   },
   "source": [
    "# Sentiment Analysis in TextBlob\n",
    "\n",
    "Okay, it's finally time to get back to the thing we really want to do in TextBlob: use its sentiment analysis package for literature!\n",
    "\n",
    "This is accessible with the `blob.sentiment`, `blob.polarity`, and `blob.subjectivity` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnSkpKn5OYyv"
   },
   "outputs": [],
   "source": [
    "pride_blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XFqMv0mOYyw"
   },
   "outputs": [],
   "source": [
    "pride_blob.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcfjX5RCOYyw"
   },
   "outputs": [],
   "source": [
    "pride_blob.subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4XESgRPOYyw"
   },
   "source": [
    "Today we are going to focus on sentiment polarity today (how positive or negative, happy or sad, a particular span of text is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNx8uOIhOYyw"
   },
   "outputs": [],
   "source": [
    "TextBlob(\"My life is ruined and I am miserable\").polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xb5iyPLIOYyx"
   },
   "outputs": [],
   "source": [
    "TextBlob(\"My life is amazing and I am overjoyed\").polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_13x9LPOYyx"
   },
   "outputs": [],
   "source": [
    "TextBlob(\"My life is not ruined and I am not miserable\").polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9l2wWpHOYyx"
   },
   "outputs": [],
   "source": [
    "TextBlob(\"My life is not amazing and I am not overjoyed\").polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxtD9IG3OYyx"
   },
   "outputs": [],
   "source": [
    "TextBlob(\"It's kind of like a potato\").polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxr1yIXpOYyx"
   },
   "source": [
    "## Creating a DataFrame of Polarity Values for *The Sign of the Four*\n",
    "\n",
    "We now have pretty much all the pieces in place to accomplish our task: creating a DataFrame in which each row contains a sentence from *The Sign of the Four* and the TextBlob polarity and subjectivity score for that sentence. Let's go!\n",
    "\n",
    "We will create three parallel lists:\n",
    "- one containing the text of every sentence, in the form of a `string`\n",
    "- one containing a polarity value for each sentence, in the form of a `float`\n",
    "- one containing a subjectivity value for each sentence, also in the form of a `float`\n",
    "\n",
    "How would we do this, using skills we learned back in the first half of the course?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXxCidM5OYyy"
   },
   "source": [
    "### Using `blob.sentences`\n",
    "\n",
    "Let's start by examining the output of TextBlob's `blob.sentences` method more closely, so we get a better sense of how we'll produce our three desired lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Re36jN6AOYyy"
   },
   "outputs": [],
   "source": [
    "sot4_sentences_blob = sot4_blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0et4DRvOYyy"
   },
   "outputs": [],
   "source": [
    "type(sot4_sentences_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "975wG44IOYyy"
   },
   "outputs": [],
   "source": [
    "sot4_sentences_blob[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rShRSOXEOYyy"
   },
   "outputs": [],
   "source": [
    "type(sot4_sentences_blob[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJk13AM4OYyy"
   },
   "outputs": [],
   "source": [
    "sot4_sentences_blob[22].polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GsrFuavWOYyz"
   },
   "outputs": [],
   "source": [
    "sot4_polarities = []\n",
    "\n",
    "for sentence in sot4_sentences_blob:\n",
    "    sot4_polarities.append(sentence.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QGPACsh7OYyz"
   },
   "outputs": [],
   "source": [
    "sot4_polarities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtwnXSK9OYyz"
   },
   "outputs": [],
   "source": [
    "sot4_subjectivities = []\n",
    "\n",
    "for sentence in sot4_sentences_blob:\n",
    "    sot4_subjectivities.append(sentence.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-veyy0RIOYyz"
   },
   "outputs": [],
   "source": [
    "sot4_subjectivities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RD4Ga2PfOYyz"
   },
   "outputs": [],
   "source": [
    "sot4_sentences_blob[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMqL61E8OYy0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sot4_sentences_blob[22].raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWcdKBvQOYy0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type(sot4_sentences_blob[22].raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xp1g9DaZOYy0"
   },
   "outputs": [],
   "source": [
    "sot4_sentences_blob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iSHJ2UXOYy0"
   },
   "outputs": [],
   "source": [
    "sot4_sentences_blob[0].raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7G-oUT_zOYy1"
   },
   "source": [
    "Since that output is a bit ugly, with all those `\\n\\n\\n`s, let's create our `string` of each sentence in a slightly different way: by using Python's `string.join()` method, which we met wayyyyy back in Week 3 (go look if you don't believe me!).\n",
    "\n",
    "Here, we'll use `string.join()` to join together all the `blob.word`s with spaces, which gives us a pretty string to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9AlyWWjOYy1"
   },
   "outputs": [],
   "source": [
    "sot4_sentences_blob[0].words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxbrd59vOYy1"
   },
   "outputs": [],
   "source": [
    "\" \".join(sot4_sentences_blob[0].words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pe3FHuhfOYy1"
   },
   "outputs": [],
   "source": [
    "type(\" \".join(sot4_sentences_blob[0].words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9JI_5F9OYy2"
   },
   "outputs": [],
   "source": [
    "sot4_sentences = []\n",
    "\n",
    "for sentence in sot4_sentences_blob:\n",
    "    sot4_sentences.append(\" \".join(sentence.words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKf01ek8OYy2"
   },
   "outputs": [],
   "source": [
    "sot4_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIThYv65OYy2"
   },
   "source": [
    "### Creating a DataFrame from Three Parallel Lists\n",
    "\n",
    "Okay, we have all the contents of our desired DataFrame.\n",
    "\n",
    "- A list containing all the sentences of *The Sign of the Four*, in order\n",
    "- A list containing the polarity values for each of those sentences, in order\n",
    "- A list containing the subjectivity values for each of those sentences, in order\n",
    "\n",
    "Our friend Pandas allows us to quite easily make a new DataFrame out of this kind of data, with its `pd.DataFrame()` method.\n",
    "\n",
    "The `pd.DataFrame()` method takes as its argument... **a dictionary**! (See why we had to finally learn about dictionaries??). It expects this argument to be formatted as follows:\n",
    "\n",
    "```\n",
    "new_df = pd.DataFrame(\n",
    "    {\n",
    "        'column1': list1,\n",
    "        'column2': list2,\n",
    "        'column3': list3\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "Of course, you could also write this same command without all the tabs and newlines as follows:\n",
    "\n",
    "`new_df = pd.DataFrame({'column1': list1, 'column2': list2, 'column3': list3})`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRWU4Y8POYy2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAytjZKJOYy2"
   },
   "outputs": [],
   "source": [
    "sot4_sentence_sentiment_df = pd.DataFrame({\n",
    "    'sentence': sot4_sentences,\n",
    "    'polarity': sot4_polarities,\n",
    "    'subjectivity': sot4_subjectivities\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRHbz-BjOYy3"
   },
   "outputs": [],
   "source": [
    "sot4_sentence_sentiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMYJiCm2OYy3"
   },
   "source": [
    "Let's now have a look at the sentences that TextBlob considers the most positive, as well as the most negative ones..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AVIIFKgOOYy3"
   },
   "outputs": [],
   "source": [
    "sot4_sentence_sentiment_df.sort_values(by='polarity', ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdWf86CrOYy3"
   },
   "source": [
    "Pretty hard to read what's in the `Sentence` column! We could export it to a CSV and explore it in Excel or Google Sheets... or we can set this Pandas parameter so that there is no maximum column width, and it will just show us everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "INuEBsM7OYy3"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uyMU62dZOYy3"
   },
   "outputs": [],
   "source": [
    "sot4_sentence_sentiment_df.sort_values(by='polarity', ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7razxciOYy4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sot4_sentence_sentiment_df.sort_values(by='polarity', ascending=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qml6WUUzBRsd"
   },
   "source": [
    "# For the most curious: how we can deal with subjectivity using VADER scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1C0p7GmyBe7b"
   },
   "source": [
    "- There is no \"subjectivity\" metrics but we can define our own looking at the dictionary with negative, positive and neutral scores VADER gives us\n",
    "- We need to define a new set of examples to compare the algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lIVGgSbBvVS"
   },
   "source": [
    "My + LLM boring set of examples (you can do much better!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKn3L20i6hJq"
   },
   "outputs": [],
   "source": [
    "examples_objectivity = [\n",
    "    \"The sun rises in the east and sets in the west.\",\n",
    "    \"The book details the origins of the solar system.\",\n",
    "    \"The experiment yielded unexpected results, showing potential errors in previous models.\",\n",
    "    \"Wow, the sunset tonight is absolutely breathtaking!\",\n",
    "    \"This study proves nothing new and is a complete waste of resources.\",\n",
    "    \"The data strongly suggests a correlation between the two variables.\",\n",
    "    \"That movie was unbelievably bad; I can't believe I wasted two hours on it!\",\n",
    "    \"I'm thrilled to finally visit Paris next week; itâ€™s been my dream for years!\",\n",
    "    \"The procedure is fairly straightforward, requiring only basic understanding of calculus.\",\n",
    "    \"I guess itâ€™s okay, but itâ€™s not as great as everyone says.\",\n",
    "    \"After reviewing all the reports, itâ€™s evident that improvements are needed.\",\n",
    "    \"Sheâ€™s just amazing; every time I see her perform, itâ€™s magical!\",\n",
    "    \"The solution is elegant and minimizes computational overhead.\",\n",
    "    \"No, just no. I cannot understand why anyone would enjoy this.\",\n",
    "    \"To be honest, the outcome was predictable and lacked excitement.\",\n",
    "    \"Their customer service is decent, but nothing extraordinary.\",\n",
    "    \"The latest model offers a marginal improvement over previous versions.\",\n",
    "    \"Reading this article was such a joy! Itâ€™s insightful and well-researched.\",\n",
    "    \"I would not recommend this product; itâ€™s just not worth the price.\",\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
